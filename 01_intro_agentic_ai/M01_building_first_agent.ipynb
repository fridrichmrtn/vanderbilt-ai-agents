{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a9e761",
   "metadata": {},
   "source": [
    "\n",
    "# Building a Simple AI Agent (Parts 1–3)\n",
    "\n",
    "This notebook combines **Part 1**, **Part 2**, and **Part 3** of the tutorial into a single, executable document.  \n",
    "You'll learn how to:\n",
    "- Structure an **agent loop**\n",
    "- **Parse** model responses\n",
    "- **Execute** tool actions\n",
    "- **Update memory**\n",
    "- Decide when to **terminate**\n",
    "\n",
    "> The examples below include a minimal, runnable mock Agent that uses simple tools (`list_files`, `read_file`) and a mock `generate_response` function to simulate an LLM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cab64e",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1 — The Agent Loop in Python\n",
    "\n",
    "The agent loop is the backbone of our AI agent, enabling it to perform tasks by combining response generation, action execution, and memory updates in an iterative process.\n",
    "\n",
    "### Steps in the Agent Loop\n",
    "\n",
    "1. **Construct Prompt**: Combine the agent’s memory, user input, and system rules into a single prompt.  \n",
    "2. **Generate Response**: Send the constructed prompt to the LLM and retrieve a response.  \n",
    "3. **Parse Response**: Extract the intended action and its parameters from the LLM’s output.  \n",
    "4. **Execute Action**: Perform the requested task with the appropriate tool.  \n",
    "5. **Convert/Store Result**: Save the result and feedback to memory.  \n",
    "6. **Continue Loop?**: Terminate if instructed or if a stopping condition is reached.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d2a233",
   "metadata": {},
   "source": [
    "\n",
    "### Agent Loop (Conceptual Example)\n",
    "```python\n",
    "# The Agent Loop\n",
    "while iterations < max_iterations:\n",
    "\n",
    "    # 1. Construct prompt: Combine agent rules with memory\n",
    "    prompt = agent_rules + memory\n",
    "\n",
    "    # 2. Generate response from LLM\n",
    "    print(\"Agent thinking...\")\n",
    "    response = generate_response(prompt)\n",
    "    print(f\"Agent response: {response}\")\n",
    "\n",
    "    # 3. Parse response to determine action\n",
    "    action = parse_action(response)\n",
    "\n",
    "    result = \"Action executed\"\n",
    "\n",
    "    if action[\"tool_name\"] == \"list_files\":\n",
    "        result = {\"result\": list_files()}\n",
    "    elif action[\"tool_name\"] == \"read_file\":\n",
    "        result = {\"result\": read_file(action[\"args\"][\"file_name\"])}\n",
    "    elif action[\"tool_name\"] == \"error\":\n",
    "        result = {\"error\": action[\"args\"][\"message\"]}\n",
    "    elif action[\"tool_name\"] == \"terminate\":\n",
    "        print(action[\"args\"][\"message\"])\n",
    "        break\n",
    "    else:\n",
    "        result = {\"error\": \"Unknown action: \" + action[\"tool_name\"]}\n",
    "\n",
    "    print(f\"Action result: {result}\")\n",
    "\n",
    "    # 5. Update memory with response and results\n",
    "    memory.extend([\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
    "    ])\n",
    "\n",
    "    # 6. Check termination condition\n",
    "    if action[\"tool_name\"] == \"terminate\":\n",
    "        break\n",
    "\n",
    "    iterations += 1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c23d557",
   "metadata": {},
   "source": [
    "\n",
    "### Constructing the Agent Prompt\n",
    "\n",
    "The prompt is created by appending the agent’s rules (system message) to the current memory of interactions:\n",
    "\n",
    "```python\n",
    "prompt = agent_rules + memory\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316504d3",
   "metadata": {},
   "source": [
    "\n",
    "### Agent Rules: Defining the Agent’s Behavior\n",
    "\n",
    "Below is a sample `agent_rules` structure included at the start of every iteration to guide the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4c0c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent rules initialized.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "agent_rules = [{\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"\"\"\n",
    "You are an AI agent that can perform tasks by using available tools.\n",
    "\n",
    "Available tools:\n",
    "- list_files() -> List[str]: List all files in the current directory.\n",
    "- read_file(file_name: str) -> str: Read the content of a file.\n",
    "- terminate(message: str): End the agent loop and print a summary to the user.\n",
    "\n",
    "If a user asks about files, list them before reading.\n",
    "\n",
    "Every response MUST have an action.\n",
    "Respond in this format:\n",
    "\n",
    "```action\n",
    "{\n",
    "    \"tool_name\": \"insert tool_name\",\n",
    "    \"args\": {...fill in any required arguments here...}\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "}]\n",
    "print(\"Agent rules initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bf3bbe",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2 — Interfacing with the Environment\n",
    "\n",
    "Once the Agent has generated a response, we interpret it as an **action** to execute in the environment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e94714",
   "metadata": {},
   "source": [
    "\n",
    "### Step 3: Parse the Response\n",
    "\n",
    "The model is expected to respond with a JSON action inside a markdown code block labeled `action`.  \n",
    "We extract that JSON and parse it into a Python dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "177283d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing utilities ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "def extract_markdown_block(text: str, fence: str) -> str:\n",
    "    \"\"\"Extract the content of a fenced code block like ```action ... ```\"\"\"\n",
    "    # Regex to capture content inside ```action ... ``` fences\n",
    "    pattern = re.compile(rf\"\"\"```{re.escape(fence)}\\s*(.*?)\\s*```\"\"\", re.DOTALL)\n",
    "    m = pattern.search(text)\n",
    "    if not m:\n",
    "        raise ValueError(f\"No fenced block labeled '{fence}' found.\")\n",
    "    return m.group(1)\n",
    "\n",
    "def parse_action(response: str) -> Dict[str, Any]:\n",
    "    \"\"\"Parse the LLM response into a structured action dictionary.\"\"\"\n",
    "    try:\n",
    "        payload = extract_markdown_block(response, \"action\")\n",
    "        response_json = json.loads(payload)\n",
    "        if \"tool_name\" in response_json and \"args\" in response_json:\n",
    "            return response_json\n",
    "        else:\n",
    "            return {\"tool_name\": \"error\", \"args\": {\"message\": \"You must respond with a JSON tool invocation.\"}}\n",
    "    except ValueError:\n",
    "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"No action block found. Respond with a JSON tool invocation.\"}}\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"tool_name\": \"error\", \"args\": {\"message\": \"Invalid JSON response. You must respond with a JSON tool invocation.\"}}\n",
    "\n",
    "print(\"Parsing utilities ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b334e30",
   "metadata": {},
   "source": [
    "\n",
    "### Step 4: Execute the Action\n",
    "\n",
    "Each `tool_name` maps to a Python function. Below we define a tiny toolset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4f18aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools ready. Demo files created in ./demo_files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Demo setup: create a few small files ---\n",
    "Path(\"demo_files\").mkdir(exist_ok=True)\n",
    "with open(\"demo_files/file1.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Hello from file1. This is a demo file.\")\n",
    "\n",
    "with open(\"demo_files/file2.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"Greetings from file2. Another demo content.\")\n",
    "\n",
    "def list_files() -> List[str]:\n",
    "    return sorted([p.name for p in Path(\"demo_files\").glob(\"*\") if p.is_file()])\n",
    "\n",
    "def read_file(file_name: str) -> str:\n",
    "    p = Path(\"demo_files\") / file_name\n",
    "    if not p.exists() or not p.is_file():\n",
    "        return f\"File '{file_name}' not found.\"\n",
    "    return p.read_text(encoding=\"utf-8\")\n",
    "\n",
    "print(\"Tools ready. Demo files created in ./demo_files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdada169",
   "metadata": {},
   "source": [
    "\n",
    "## Part 3 — Memory & Termination\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649f19de",
   "metadata": {},
   "source": [
    "\n",
    "### Step 5: Update the Agent’s Memory\n",
    "\n",
    "After executing an action, we append both the agent’s intent (the LLM response) and the result of the action to memory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bda425",
   "metadata": {},
   "source": [
    "\n",
    "### Step 6: Decide Whether to Continue\n",
    "\n",
    "The loop terminates if it receives a `terminate` action or a stopping condition (like `max_iterations`) is met.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9293057e",
   "metadata": {},
   "source": [
    "\n",
    "## End-to-End Demo\n",
    "\n",
    "Below is a **fully runnable** mini-agent demonstrating the entire loop with a **mock** `generate_response` function that simulates an LLM.  \n",
    "The mock policy is simple:\n",
    "- If we haven't listed files yet, respond with `list_files`.\n",
    "- If we have listed files but haven't read one, respond with `read_file` for the first file.\n",
    "- After reading, respond with `terminate` and a short message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904c8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent thinking...\n",
      "Agent response: ```action\n",
      "{\"tool_name\": \"list_files\", \"args\": {}}\n",
      "```\n",
      "Action result: {'result': ['file1.txt', 'file2.txt']}\n",
      "Agent thinking...\n",
      "Agent response: ```action\n",
      "{\"tool_name\": \"list_files\", \"args\": {}}\n",
      "```\n",
      "Action result: {'result': ['file1.txt', 'file2.txt']}\n",
      "Agent thinking...\n",
      "Agent response: ```action\n",
      "{\"tool_name\": \"list_files\", \"args\": {}}\n",
      "```\n",
      "Action result: {'result': ['file1.txt', 'file2.txt']}\n",
      "Agent thinking...\n",
      "Agent response: ```action\n",
      "{\"tool_name\": \"list_files\", \"args\": {}}\n",
      "```\n",
      "Action result: {'result': ['file1.txt', 'file2.txt']}\n",
      "Agent thinking...\n",
      "Agent response: ```action\n",
      "{\"tool_name\": \"list_files\", \"args\": {}}\n",
      "```\n",
      "Action result: {'result': ['file1.txt', 'file2.txt']}\n",
      "\n",
      "Final memory transcript:\n",
      "{'role': 'user', 'content': 'What files are in this directory?'}\n",
      "{'role': 'assistant', 'content': '```action\\n{\"tool_name\": \"list_files\", \"args\": {}}\\n```'}\n",
      "{'role': 'user', 'content': '{\"result\": [\"file1.txt\", \"file2.txt\"]}'}\n",
      "{'role': 'assistant', 'content': '```action\\n{\"tool_name\": \"list_files\", \"args\": {}}\\n```'}\n",
      "{'role': 'user', 'content': '{\"result\": [\"file1.txt\", \"file2.txt\"]}'}\n",
      "{'role': 'assistant', 'content': '```action\\n{\"tool_name\": \"list_files\", \"args\": {}}\\n```'}\n",
      "{'role': 'user', 'content': '{\"result\": [\"file1.txt\", \"file2.txt\"]}'}\n",
      "{'role': 'assistant', 'content': '```action\\n{\"tool_name\": \"list_files\", \"args\": {}}\\n```'}\n",
      "{'role': 'user', 'content': '{\"result\": [\"file1.txt\", \"file2.txt\"]}'}\n",
      "{'role': 'assistant', 'content': '```action\\n{\"tool_name\": \"list_files\", \"args\": {}}\\n```'}\n",
      "{'role': 'user', 'content': '{\"result\": [\"file1.txt\", \"file2.txt\"]}'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_response(prompt_messages: List[Dict[str, Any]]) -> str:\n",
    "    \"\"\"A tiny mock LLM that decides next action from memory in prompt_messages.\"\"\"\n",
    "    # Find last user feedback (which usually contains results) and last assistant action\n",
    "    last_user = None\n",
    "    last_assistant_action = None\n",
    "    for msg in reversed(prompt_messages):\n",
    "        if msg.get(\"role\") == \"user\" and last_user is None:\n",
    "            last_user = msg.get(\"content\")\n",
    "        if msg.get(\"role\") == \"assistant\" and last_assistant_action is None:\n",
    "            last_assistant_action = msg.get(\"content\")\n",
    "        if last_user and last_assistant_action:\n",
    "            break\n",
    "\n",
    "    # Heuristics\n",
    "    try:\n",
    "        # If we already got a list of files as user feedback, try to read the first file\n",
    "        if last_user and last_user.strip().startswith(\"[\") and \"file\" in last_user:\n",
    "            files = json.loads(last_user)\n",
    "            if isinstance(files, list) and files:\n",
    "                action = {\n",
    "                    \"tool_name\": \"read_file\",\n",
    "                    \"args\": {\"file_name\": files[0]}\n",
    "                }\n",
    "                return f\"\"\"```action\n",
    "{json.dumps(action)}\n",
    "```\"\"\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # If we already read a file, terminate\n",
    "    if last_assistant_action and \"read_file\" in last_assistant_action:\n",
    "        action = {\"tool_name\": \"terminate\", \"args\": {\"message\": \"Finished reading a file. Goodbye!\"}}\n",
    "        return f\"\"\"```action\n",
    "{json.dumps(action)}\n",
    "```\"\"\"\n",
    "\n",
    "    # Default: list files\n",
    "    action = {\"tool_name\": \"list_files\", \"args\": {}}\n",
    "    return f\"\"\"```action\n",
    "{json.dumps(action)}\n",
    "```\"\"\"\n",
    "\n",
    "# --- Full loop ---\n",
    "memory: List[Dict[str, Any]] = [\n",
    "    {\"role\": \"user\", \"content\": \"What files are in this directory?\"}\n",
    "]\n",
    "max_iterations = 5\n",
    "iterations = 0\n",
    "\n",
    "while iterations < max_iterations:\n",
    "    # 1) Construct prompt (rules + memory)\n",
    "    prompt = agent_rules + memory\n",
    "\n",
    "    # 2) Generate response (mock LLM)\n",
    "    print(\"Agent thinking...\")\n",
    "    response = generate_response(prompt)\n",
    "    print(\"Agent response:\", response.strip())\n",
    "\n",
    "    # 3) Parse\n",
    "    action = parse_action(response)\n",
    "\n",
    "    # 4) Execute\n",
    "    if action[\"tool_name\"] == \"list_files\":\n",
    "        result = {\"result\": list_files()}\n",
    "    elif action[\"tool_name\"] == \"read_file\":\n",
    "        result = {\"result\": read_file(action[\"args\"].get(\"file_name\", \"\"))}\n",
    "    elif action[\"tool_name\"] == \"error\":\n",
    "        result = {\"error\": action[\"args\"][\"message\"]}\n",
    "    elif action[\"tool_name\"] == \"terminate\":\n",
    "        print(action[\"args\"][\"message\"])\n",
    "        # Update memory before breaking, so the transcript is complete\n",
    "        memory.extend([\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "            {\"role\": \"user\", \"content\": json.dumps({\"message\": action[\"args\"][\"message\"]})}\n",
    "        ])\n",
    "        break\n",
    "    else:\n",
    "        result = {\"error\": \"Unknown action: \" + str(action.get(\"tool_name\"))}\n",
    "\n",
    "    print(\"Action result:\", result)\n",
    "\n",
    "    # 5) Update memory\n",
    "    memory.extend([\n",
    "        {\"role\": \"assistant\", \"content\": response},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(result)}\n",
    "    ])\n",
    "\n",
    "    # 6) Check termination (also handled above)\n",
    "    if action[\"tool_name\"] == \"terminate\":\n",
    "        break\n",
    "\n",
    "    iterations += 1\n",
    "\n",
    "print(\"\\nFinal memory transcript:\")\n",
    "for m in memory:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396a5bf9",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "_Exported on 2025-09-11 04:36:28 UTC_\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
