{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18684078",
   "metadata": {},
   "source": [
    "# Concepts of Agentic AI\n",
    "\n",
    "* agentic ai behaves with agency and autonomy, can problem-solve and react to different real-life situation\n",
    "* flipped interaction pattern -> agentic system interacts with humans and other systems, without us necessary telling it what to do, in order to accomplish a goal we gave it\n",
    "\n",
    "* agent loop (general)\n",
    "    * human sets a goal\n",
    "    * ai takes actions towards the goal using available resources (APIs, SQLs, etc)\n",
    "        * prompt -> response -> action\n",
    "        * get feedback on result from ai\n",
    "    * termination criteria reached, return result\n",
    "\n",
    "* agent loop\n",
    "    * construct prompt\n",
    "    * generate response\n",
    "    * parse response\n",
    "    * execute action\n",
    "    * convert results to string\n",
    "    * continue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f15747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "with open(\"openai_token\", \"r\") as file:\n",
    "    openai_token = file.read().strip()\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e6b060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZGVmIHN3YXBfZGljdChkKTogDQogICAgcmV0dXJuIHt2OiBrIGZvciBrLCB2IGluIGQuaXRlbXMoKX0=\n"
     ]
    }
   ],
   "source": [
    "# scaffolding example\n",
    "import base64\n",
    "from typing import List, Dict\n",
    "from litellm import completion\n",
    "\n",
    "def generate_response(messages:List[Dict]) -> str:\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "        #temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming. Return Base64 encoded string only\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"}\n",
    "]\n",
    "\n",
    "response = generate_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4370a1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "def swap_keys_values(d):\n",
      "    \"\"\"\n",
      "    Swaps the keys and values in a dictionary where all values are unique.\n",
      "    \n",
      "    Parameters:\n",
      "    d (dict): A dictionary with unique values.\n",
      "    \n",
      "    Returns:\n",
      "    dict: A new dictionary with keys and values swapped. The original values become keys,\n",
      "          and the original keys become values.\n",
      "    \n",
      "    Example:\n",
      "    >>> swap_keys_values({'a': 1, 'b': 2, 'c': 3})\n",
      "    {1: 'a', 2: 'b', 3: 'c'}\n",
      "    \"\"\"\n",
      "    return {value: key for key, value in d.items()}\n",
      "```\n",
      "\n",
      "This function creates a new dictionary by iterating over the items of the input dictionary and constructs key-value pairs by reversing the original key-value relationship. Since the original values are required to be unique, they can safely be used as keys in the new dictionary.\n"
     ]
    }
   ],
   "source": [
    "# lets try a bit of programmatic prompting\n",
    "import json\n",
    "\n",
    "code_spec = {\n",
    "    \"name\": \"swap_keys_values\",\n",
    "    \"description\": \"A function that swaps the keys and values in a dictionary.\",\n",
    "    \"parameters\": {\n",
    "        \"d\": \"A dictionary with unique values.\"}\n",
    "    }\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are an expert software engineer that writes clean functional code. You always document your functions.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Please implement: {json.dumps(code_spec)}\"}\n",
    "]\n",
    "\n",
    "response = generate_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2380a6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! The function already contains a docstring for documentation, but let me expand it a little further to make it more comprehensive, detailing more about the assumptions and functionality:\n",
      "\n",
      "```python\n",
      "def swap_keys_values(d):\n",
      "    \"\"\"\n",
      "    Swaps the keys and values in a dictionary, assuming all values are unique.\n",
      "    \n",
      "    Parameters:\n",
      "    d (dict): A dictionary where all the values are unique and hashable. \n",
      "    \n",
      "    Returns:\n",
      "    dict: A new dictionary with the keys and values swapped. The values of the input\n",
      "          dictionary become the keys, and the keys become the corresponding values.\n",
      "          \n",
      "    Raises:\n",
      "    ValueError: If any duplicates are found among the values in the input dictionary,\n",
      "                as they would cause collisions in the new dictionary where those values\n",
      "                become keys.\n",
      "\n",
      "    Example:\n",
      "    >>> swap_keys_values({'a': 1, 'b': 2, 'c': 3})\n",
      "    {1: 'a', 2: 'b', 3: 'c'}\n",
      "\n",
      "    Note:\n",
      "    - This function assumes that all values in the input dictionary are unique and hashable.\n",
      "    - If there's a possibility of duplicate values, you should handle it prior to calling\n",
      "      this function or modify the function to perhaps collect all keys for each value.\n",
      "    \"\"\"\n",
      "    if len(set(d.values())) != len(d):\n",
      "        raise ValueError(\"Duplicate values found in the dictionary. All values must be unique.\")\n",
      "    \n",
      "    return {value: key for key, value in d.items()}\n",
      "```\n",
      "\n",
      "This updated version of the function includes a check for duplicates and raises a `ValueError` if duplicates are detected, preventing collisions in the resulted swapped dictionary. The docstring now clearly explains this behavioral aspect, providing additional guidance to users about the function's assumptions and constraints.\n"
     ]
    }
   ],
   "source": [
    "# models do not recall previous conversations, so they need to be supplied in the messaging part\n",
    "messages = [\n",
    "   {\"role\": \"system\", \"content\": \"You are an expert software engineer that prefers functional programming.\"},\n",
    "   {\"role\": \"user\", \"content\": \"Write a function to swap the keys and values in a dictionary.\"},\n",
    "   \n",
    "   # Here is the assistant's response from the previous step\n",
    "   # with the code. This gives it \"memory\" of the previous\n",
    "   # interaction.\n",
    "   {\"role\": \"assistant\", \"content\": response},\n",
    "   {\"role\": \"user\", \"content\": \"Update the function to include documentation.\"}\n",
    "]\n",
    "\n",
    "response = generate_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e5a6fd",
   "metadata": {},
   "source": [
    "* system -> setting up the agent, most important part\n",
    "* user -> user inputs\n",
    "* assistant -> agent outputs  \n",
    "**-> memory through user + assistant history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "662d2c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Dict\n",
    "from litellm import completion\n",
    "\n",
    "\n",
    "def generate_response(messages:List[Dict]) -> str:\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "        #temperature=0.7\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee81704e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter function description:\n",
      "from sklearn.model_selection import RandomizedSearchCV\n",
      "\n",
      "\n",
      "def random_hyperparam_optimization(model, param_distributions, X_train, y_train,\n",
      "                                   cv=5, scoring='accuracy', n_iter=10, random_state=None, n_jobs=-1):\n",
      "    \"\"\"\n",
      "    Perform random hyperparameter optimization for a given model.\n",
      "\n",
      "    Parameters:\n",
      "    - model: The machine learning model instance (e.g., RandomForestClassifier).\n",
      "    - param_distributions: Dictionary with parameters names as keys and distributions or lists of parameters to try.\n",
      "    - X_train: Training feature data.\n",
      "    - y_train: Training labels.\n",
      "    - cv: Number of cross-validation folds. Default is 5.\n",
      "    - scoring: A single string to evaluate the predictions on the test set. Default is 'accuracy'.\n",
      "    - n_iter: Number of parameter settings that are sampled. Default is 10.\n",
      "    - random_state: Seed for random number generation. Default is None.\n",
      "    - n_jobs: Number of jobs to run in parallel. Default is -1 (use all processors).\n",
      "\n",
      "    Returns:\n",
      "    - best_model: The model with the best hyperparameters found.\n",
      "    - best_params: The parameters of the best model.\n",
      "    - best_score: The best score achieved using the best model on the test set.\n",
      "    \"\"\"\n",
      "    random_search = RandomizedSearchCV(\n",
      "        estimator=model,\n",
      "        param_distributions=param_distributions,\n",
      "        n_iter=n_iter,\n",
      "        cv=cv,\n",
      "        scoring=scoring,\n",
      "        random_state=random_state,\n",
      "        n_jobs=n_jobs\n",
      "    )\n",
      "\n",
      "    random_search.fit(X_train, y_train)\n",
      "\n",
      "    best_model = random_search.best_estimator_\n",
      "    best_params = random_search.best_params_\n",
      "    best_score = random_search.best_score_\n",
      "\n",
      "    return best_model, best_params, best_score\n",
      "from sklearn.model_selection import RandomizedSearchCV\n",
      "\n",
      "\n",
      "def random_hyperparam_optimization(model, param_distributions, X_train, y_train,\n",
      "                                   cv=5, scoring='accuracy', n_iter=10, random_state=None, n_jobs=-1):\n",
      "    \"\"\"\n",
      "    Perform random hyperparameter optimization for a given model using RandomizedSearchCV.\n",
      "\n",
      "    Parameters:\n",
      "    ----------\n",
      "    model : estimator object\n",
      "        The machine learning model instance (e.g., RandomForestClassifier) from sklearn.\n",
      "    \n",
      "    param_distributions : dict\n",
      "        Dictionary with parameter names (str) as keys and lists of parameter settings to try as values.\n",
      "        Each key-value pair defines one parameter and its possible values.\n",
      "    \n",
      "    X_train : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "        The training input samples.\n",
      "    \n",
      "    y_train : array-like, shape (n_samples,)\n",
      "        The target values (class labels) as integers or strings.\n",
      "    \n",
      "    cv : int, default=5\n",
      "        Determines the cross-validation splitting strategy. Specify the number of folds.\n",
      "    \n",
      "    scoring : str or callable, default='accuracy'\n",
      "        A string or a scorer callable object/function with signature `scorer(estimator, X, y)`.\n",
      "    \n",
      "    n_iter : int, default=10\n",
      "        Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the randomness of the search. Pass an int for reproducible output.\n",
      "    \n",
      "    n_jobs : int, default=-1\n",
      "        Number of jobs to run in parallel. -1 means using all processors.\n",
      "\n",
      "    Returns:\n",
      "    -------\n",
      "    best_model : fitted estimator\n",
      "        The model instance with the best found hyperparameters.\n",
      "\n",
      "    best_params : dict\n",
      "        Parameter setting that gave the best results on the hold out data.\n",
      "\n",
      "    best_score : float\n",
      "        Mean cross-validated score of the best_estimator.\n",
      "\n",
      "    Example Usage:\n",
      "    -------------\n",
      "    >>> from sklearn.ensemble import RandomForestClassifier\n",
      "    >>> model = RandomForestClassifier()\n",
      "    >>> param_distributions = {\n",
      "    ...     'n_estimators': [10, 50, 100],\n",
      "    ...     'max_depth': [5, 10, None]\n",
      "    ... }\n",
      "    >>> X_train, y_train = load_training_data()  # Replace with your data loading function\n",
      "    >>> best_model, best_params, best_score = random_hyperparam_optimization(\n",
      "    ...     model, param_distributions, X_train, y_train, cv=3, n_iter=5)\n",
      "    >>> print(best_params)\n",
      "    {'n_estimators': 50, 'max_depth': None}\n",
      "    >>> print(best_score)\n",
      "    0.85\n",
      "\n",
      "    Edge Cases:\n",
      "    ----------\n",
      "    - If `param_distributions` is empty, RandomSearchCV will raise a ValueError.\n",
      "    - Ensure `X_train` and `y_train` have matching dimensions and contain valid data.\n",
      "    - If `n_iter` is larger than the possible number of parameter combinations, it might raise a warning but will still function.\n",
      "    - Passing incorrect type for model or param_distributions will raise a TypeError.\n",
      "    \"\"\"\n",
      "\n",
      "    random_search = RandomizedSearchCV(\n",
      "        estimator=model,\n",
      "        param_distributions=param_distributions,\n",
      "        n_iter=n_iter,\n",
      "        cv=cv,\n",
      "        scoring=scoring,\n",
      "        random_state=random_state,\n",
      "        n_jobs=n_jobs\n",
      "    )\n",
      "\n",
      "    random_search.fit(X_train, y_train)\n",
      "\n",
      "    best_model = random_search.best_estimator_\n",
      "    best_params = random_search.best_params_\n",
      "    best_score = random_search.best_score_\n",
      "\n",
      "    return best_model, best_params, best_score\n",
      "import unittest\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.datasets import make_classification\n",
      "from sklearn.exceptions import NotFittedError\n",
      "\n",
      "\n",
      "class TestRandomHyperparamOptimization(unittest.TestCase):\n",
      "    def setUp(self):\n",
      "        # Create a toy dataset for testing\n",
      "        self.X_train, self.y_train = make_classification(n_samples=100, n_features=10, random_state=42)\n",
      "\n",
      "    def test_typical_usage(self):\n",
      "        model = RandomForestClassifier()\n",
      "        param_distributions = {'n_estimators': [10, 50], 'max_depth': [5, None]}\n",
      "        best_model, best_params, best_score = random_hyperparam_optimization(\n",
      "            model, param_distributions, self.X_train, self.y_train,\n",
      "            cv=3, scoring='accuracy', n_iter=2, random_state=42\n",
      "        )\n",
      "        self.assertIn(best_params['n_estimators'], [10, 50])\n",
      "        self.assertIn(best_params['max_depth'], [5, None])\n",
      "        self.assertIsInstance(best_score, float)\n",
      "        self.assertTrue(best_score >= 0)\n",
      "\n",
      "    def test_empty_param_distributions(self):\n",
      "        model = RandomForestClassifier()\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(model, {}, self.X_train, self.y_train)\n",
      "\n",
      "    def test_invalid_n_iter(self):\n",
      "        model = RandomForestClassifier()\n",
      "        param_distributions = {'n_estimators': [10]}\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(\n",
      "                model, param_distributions, self.X_train, self.y_train, n_iter=0\n",
      "            )\n",
      "\n",
      "    def test_invalid_model(self):\n",
      "        param_distributions = {'n_estimators': [10]}\n",
      "        with self.assertRaises(TypeError):\n",
      "            random_hyperparam_optimization(\n",
      "                None, param_distributions, self.X_train, self.y_train\n",
      "            )\n",
      "\n",
      "    def test_invalid_data(self):\n",
      "        model = RandomForestClassifier()\n",
      "        param_distributions = {'n_estimators': [10]}\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(model, param_distributions, None, None)\n",
      "\n",
      "    def test_invalid_param_distributions(self):\n",
      "        model = RandomForestClassifier()\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(model, {'invalid_param': None}, self.X_train, self.y_train)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "\n",
      "\n",
      "Function and tests written to random_hyperparam_optimization.py\n",
      "\n",
      "Function:\n",
      " from sklearn.model_selection import RandomizedSearchCV\n",
      "\n",
      "\n",
      "def random_hyperparam_optimization(model, param_distributions, X_train, y_train,\n",
      "                                   cv=5, scoring='accuracy', n_iter=10, random_state=None, n_jobs=-1):\n",
      "    \"\"\"\n",
      "    Perform random hyperparameter optimization for a given model using RandomizedSearchCV.\n",
      "\n",
      "    Parameters:\n",
      "    ----------\n",
      "    model : estimator object\n",
      "        The machine learning model instance (e.g., RandomForestClassifier) from sklearn.\n",
      "    \n",
      "    param_distributions : dict\n",
      "        Dictionary with parameter names (str) as keys and lists of parameter settings to try as values.\n",
      "        Each key-value pair defines one parameter and its possible values.\n",
      "    \n",
      "    X_train : array-like or sparse matrix, shape (n_samples, n_features)\n",
      "        The training input samples.\n",
      "    \n",
      "    y_train : array-like, shape (n_samples,)\n",
      "        The target values (class labels) as integers or strings.\n",
      "    \n",
      "    cv : int, default=5\n",
      "        Determines the cross-validation splitting strategy. Specify the number of folds.\n",
      "    \n",
      "    scoring : str or callable, default='accuracy'\n",
      "        A string or a scorer callable object/function with signature `scorer(estimator, X, y)`.\n",
      "    \n",
      "    n_iter : int, default=10\n",
      "        Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.\n",
      "    \n",
      "    random_state : int, RandomState instance or None, default=None\n",
      "        Controls the randomness of the search. Pass an int for reproducible output.\n",
      "    \n",
      "    n_jobs : int, default=-1\n",
      "        Number of jobs to run in parallel. -1 means using all processors.\n",
      "\n",
      "    Returns:\n",
      "    -------\n",
      "    best_model : fitted estimator\n",
      "        The model instance with the best found hyperparameters.\n",
      "\n",
      "    best_params : dict\n",
      "        Parameter setting that gave the best results on the hold out data.\n",
      "\n",
      "    best_score : float\n",
      "        Mean cross-validated score of the best_estimator.\n",
      "\n",
      "    Example Usage:\n",
      "    -------------\n",
      "    >>> from sklearn.ensemble import RandomForestClassifier\n",
      "    >>> model = RandomForestClassifier()\n",
      "    >>> param_distributions = {\n",
      "    ...     'n_estimators': [10, 50, 100],\n",
      "    ...     'max_depth': [5, 10, None]\n",
      "    ... }\n",
      "    >>> X_train, y_train = load_training_data()  # Replace with your data loading function\n",
      "    >>> best_model, best_params, best_score = random_hyperparam_optimization(\n",
      "    ...     model, param_distributions, X_train, y_train, cv=3, n_iter=5)\n",
      "    >>> print(best_params)\n",
      "    {'n_estimators': 50, 'max_depth': None}\n",
      "    >>> print(best_score)\n",
      "    0.85\n",
      "\n",
      "    Edge Cases:\n",
      "    ----------\n",
      "    - If `param_distributions` is empty, RandomSearchCV will raise a ValueError.\n",
      "    - Ensure `X_train` and `y_train` have matching dimensions and contain valid data.\n",
      "    - If `n_iter` is larger than the possible number of parameter combinations, it might raise a warning but will still function.\n",
      "    - Passing incorrect type for model or param_distributions will raise a TypeError.\n",
      "    \"\"\"\n",
      "\n",
      "    random_search = RandomizedSearchCV(\n",
      "        estimator=model,\n",
      "        param_distributions=param_distributions,\n",
      "        n_iter=n_iter,\n",
      "        cv=cv,\n",
      "        scoring=scoring,\n",
      "        random_state=random_state,\n",
      "        n_jobs=n_jobs\n",
      "    )\n",
      "\n",
      "    random_search.fit(X_train, y_train)\n",
      "\n",
      "    best_model = random_search.best_estimator_\n",
      "    best_params = random_search.best_params_\n",
      "    best_score = random_search.best_score_\n",
      "\n",
      "    return best_model, best_params, best_score\n",
      "\n",
      "Tests:\n",
      " import unittest\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.datasets import make_classification\n",
      "from sklearn.exceptions import NotFittedError\n",
      "\n",
      "\n",
      "class TestRandomHyperparamOptimization(unittest.TestCase):\n",
      "    def setUp(self):\n",
      "        # Create a toy dataset for testing\n",
      "        self.X_train, self.y_train = make_classification(n_samples=100, n_features=10, random_state=42)\n",
      "\n",
      "    def test_typical_usage(self):\n",
      "        model = RandomForestClassifier()\n",
      "        param_distributions = {'n_estimators': [10, 50], 'max_depth': [5, None]}\n",
      "        best_model, best_params, best_score = random_hyperparam_optimization(\n",
      "            model, param_distributions, self.X_train, self.y_train,\n",
      "            cv=3, scoring='accuracy', n_iter=2, random_state=42\n",
      "        )\n",
      "        self.assertIn(best_params['n_estimators'], [10, 50])\n",
      "        self.assertIn(best_params['max_depth'], [5, None])\n",
      "        self.assertIsInstance(best_score, float)\n",
      "        self.assertTrue(best_score >= 0)\n",
      "\n",
      "    def test_empty_param_distributions(self):\n",
      "        model = RandomForestClassifier()\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(model, {}, self.X_train, self.y_train)\n",
      "\n",
      "    def test_invalid_n_iter(self):\n",
      "        model = RandomForestClassifier()\n",
      "        param_distributions = {'n_estimators': [10]}\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(\n",
      "                model, param_distributions, self.X_train, self.y_train, n_iter=0\n",
      "            )\n",
      "\n",
      "    def test_invalid_model(self):\n",
      "        param_distributions = {'n_estimators': [10]}\n",
      "        with self.assertRaises(TypeError):\n",
      "            random_hyperparam_optimization(\n",
      "                None, param_distributions, self.X_train, self.y_train\n",
      "            )\n",
      "\n",
      "    def test_invalid_data(self):\n",
      "        model = RandomForestClassifier()\n",
      "        param_distributions = {'n_estimators': [10]}\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(model, param_distributions, None, None)\n",
      "\n",
      "    def test_invalid_param_distributions(self):\n",
      "        model = RandomForestClassifier()\n",
      "        with self.assertRaises(ValueError):\n",
      "            random_hyperparam_optimization(model, {'invalid_param': None}, self.X_train, self.y_train)\n",
      "\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    unittest.main()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def develop_custom_function():\n",
    "    print(\"Enter function description:\")\n",
    "    user_input = input().strip()\n",
    "\n",
    "    # first prompt\n",
    "    messages = [\n",
    "    {\"role\": \"system\",\n",
    "        \"content\":\n",
    "            \"\"\"You are an expert software engineer that prefers functional\n",
    "            programming.You return parsable json only, with explanations under\n",
    "            key exp, code under key code, and func name under key name.\"\"\"},\n",
    "    {\"role\": \"user\",\n",
    "        \"content\":\n",
    "            user_input}]\n",
    "\n",
    "    response = generate_response(messages)\n",
    "    initial_func = json.loads(response)[\"code\"]\n",
    "    func_name = json.loads(response)[\"name\"]\n",
    "    print(initial_func)\n",
    "\n",
    "    # second prompt, with memory of the first\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    messages.append({\"role\": \"user\", \"content\":\n",
    "            \"\"\"Update the function to include clean documentation string,\n",
    "            parameter descriptions, return value description,\n",
    "            example usage, edge cases.\"\"\"})\n",
    "\n",
    "    response = generate_response(messages)\n",
    "    documented_func = json.loads(response)[\"code\"]\n",
    "    print(documented_func)\n",
    "\n",
    "    # third prompt, with memory of the first and second\n",
    "    messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "    messages.append({\"role\": \"user\", \"content\":\n",
    "        \"\"\"Generate unit test for the function using unittest framework,\n",
    "        test should cover typical usage, edge cases, error cases and various\n",
    "        input types\"\"\"})\n",
    "\n",
    "    response = generate_response(messages)\n",
    "    test_cases = json.loads(response)[\"code\"]\n",
    "    print(test_cases)\n",
    "    # \n",
    "    file_name = func_name+\".py\"\n",
    "    with open(file_name, \"w\") as file:\n",
    "        file.write(documented_func)\n",
    "        file.write(\"\\n\\n\")\n",
    "        file.write(test_cases)\n",
    "\n",
    "    return documented_func, test_cases, file_name\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    func, tests, file_name = develop_custom_function()\n",
    "    print(f\"\\nFunction and tests written to {file_name}\")\n",
    "    print(\"\\nFunction:\\n\", func)\n",
    "    print(\"\\nTests:\\n\", tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ae4110",
   "metadata": {},
   "source": [
    "# Adding structure to AI Agents Outputs\n",
    "\n",
    "* how to prompt a model to get an action that can be executed on behalf of the agent\n",
    "* AI (LLMs) vs Environment interface (executing actions)\n",
    "    * Prompt engineering + parsing\n",
    "    * LLMs that support function calls\n",
    "\n",
    "\n",
    "### Prompt engineering + parsing\n",
    "\n",
    "* construct prompt\n",
    "    * consistant format of the response\n",
    "    * create template to follow (action:object)\n",
    "    * LLMs can follow instructions (placeholders) nicely\n",
    "* generate response\n",
    "* parse response\n",
    "    * rigorous, strict output format"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
