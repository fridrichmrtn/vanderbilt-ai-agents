{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c894db2",
   "metadata": {},
   "source": [
    "# Extending AI agents with self-prompting\n",
    "\n",
    "* prompts as operation (computation)\n",
    "    * synthetic data generation (generate file paths)\n",
    "    * data organization (ie organize list of files to dir based on their type or work/leisure activity)\n",
    "    * policy understanding and compliance reasoning (upload doc & receipt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee4da9",
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "source": [
    "### Self-Prompting Agents: Harnessing LLMs for Specialized Tasks\n",
    "\n",
    "Large language models have emerged as remarkably versatile computational tools, capable of tasks ranging from sophisticated analysis to creative generation. Through careful prompting, we can use these models to perform natural language processing tasks like sentiment analysis and text classification, engage in analytical reasoning for problem-solving, generate structured data from unstructured text, and even act as domain experts in fields like software architecture or cybersecurity.\n",
    "\n",
    "This computational flexibility stems from the models’ ability to understand and follow complex instructions, maintain context through multi-turn interactions, and adapt their outputs to specific formats and requirements. For example, the same underlying model can transform unstructured data into JSON, generate visualizations through tools like Graphviz, provide expert analysis in specialized domains, and even create interactive experiences like educational games or simulated systems.\n",
    "\n",
    "#### The Challenge of Clean Architecture\n",
    "\n",
    "However, this power presents a challenge. If we simply tell our agent to “think like a marketing expert” or “analyze like a data scientist,” we risk muddying its decision-making process. The agent’s primary job is to coordinate actions and achieve goals, not to become entangled in domain-specific reasoning. We need to maintain a clear separation between the agent’s strategic thinking and the specialized analytical capabilities we want to leverage.\n",
    "\n",
    "Consider a company’s organizational structure: A CEO doesn’t need to be an expert in marketing, engineering, and finance. Instead, they need to understand when to consult their experts in each department and how to coordinate their inputs toward company goals. Our agent should work the same way – maintaining clear decision-making while having access to specialized capabilities through well-defined interfaces.\n",
    "\n",
    "The solution is to isolate these prompts that are focused on specific tasks and expose them as tools. By doing this, we can keep the agent’s architecture clean and focused on its primary role of coordinating actions, while still leveraging the full power of LLM-based computation when needed.\n",
    "\n",
    "#### Understanding Self-Dialog\n",
    "\n",
    "When we expose “prompting” as a tool to the agent, we are allowing it to engage in “self-dialog.” Essentially, it is using its own capabilities to prompt itself for specialized tasks. This pattern enables the agent to dynamically adopt expert personas, perform complex analysis, and generate structured content, all while maintaining a clear separation between strategic decision-making and specialized processing.\n",
    "\n",
    "In this tutorial, we’ll explore how to implement this pattern effectively, create different types of LLM-based tools for specialized tasks, and combine these tools to solve complex problems. By treating LLMs as tools within our agent’s toolkit, we can extend its capabilities while keeping its architecture clean and focused.\n",
    "\n",
    "The LLM can:\n",
    "\n",
    "* Transform unstructured data into structured formats by thinking through the patterns and relationships\n",
    "* Analyze sentiment and emotion by carefully considering language nuances and context\n",
    "* Generate creative solutions by exploring possibilities from multiple perspectives\n",
    "* Extract key insights by systematically examining information through different analytical frameworks\n",
    "* Clean and normalize data by applying consistent rules and handling edge cases thoughtfully\n",
    "\n",
    "For example, when analyzing customer feedback, the LLM might first organize the raw text into structured categories, then analyze sentiment in each category, and finally synthesize insights about customer satisfaction trends. Each step involves the LLM engaging in a different type of analytical thinking.\n",
    "\n",
    "#### The Tool-Based Solution\n",
    "\n",
    "We can achieve this balance by exposing the LLM’s capabilities as tools. This approach allows us to:\n",
    "\n",
    "* Keep the agent’s decision-making process clean and focused on coordinating actions\n",
    "* Access the full power of LLM-based analysis and transformation when needed\n",
    "* Maintain clear boundaries between strategic coordination and specialized processing\n",
    "* Create reusable, well-defined interfaces for common analytical tasks\n",
    "\n",
    "Think of these tools as specialized departments in our organization. Each has a clear purpose and interface, but the internal workings – the specific prompts and chains of reasoning – are encapsulated within the tool itself. The agent doesn’t need to know how the sentiment analysis tool works internally; it just needs to know when to use it and what to expect from it.\n",
    "\n",
    "#### Building a Toolkit\n",
    "\n",
    "We can create different types of LLM-based tools to handle various specialized tasks:\n",
    "\n",
    "* **Transformation Tools:** Converting between different data formats and structures\n",
    "* **Analysis Tools:** Providing expert insight in specific domains\n",
    "* **Generation Tools:** Creating structured content from specifications\n",
    "* **Validation Tools:** Checking if content meets specific criteria\n",
    "* **Extraction Tools:** Pulling specific information from larger contexts\n",
    "\n",
    "Each tool type encapsulates a specific kind of self-dialog, making it available to the agent through a clean interface. This allows us to leverage the LLM’s sophisticated reasoning capabilities while maintaining architectural clarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8055ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### Tools vs unstructured data and prompting\n",
    "\n",
    "* prompt as a bridge between unstructured real-world and computer tools\n",
    "* ability to extract information from unstructured (photo of a room, website) to structured (json) form\n",
    "* prompt-based tools to reshape/convert unstructured to structured info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c741cda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### A Self-Prompting Example\n",
    "\n",
    "Imagine we’re building an agent to automate accounts payable processing. Every day, the agent receives dozens of emails with attached invoices from different vendors, each using their own unique format and layout. Some are PDFs, others are scanned images that have been converted to text, and a few even arrive as plain text in the email body. Our agent needs to understand each invoice, extract key information like the invoice number, date, amount, and line items, and then insert this data into the company’s accounting database. Without automation, this would be a tedious manual task requiring someone to read each invoice and transcribe the important details.\n",
    "\n",
    "This is where the computational power of large language models becomes transformative. Through self-prompting, our agent can use an LLM as a universal parser that understands the natural structure of invoices, regardless of their format. The LLM can read an invoice like a human would, identifying key information based on context and common patterns, then output that information in a structured format our agent can process. We don’t need to write separate parsers for each vendor’s invoice format or maintain complex rules about where to find specific information — the LLM can handle all of that complexity for us.\n",
    "\n",
    "Here’s how we can implement this capability as a reusable tool for our agent:\n",
    "\n",
    "````python\n",
    "@register_tool()\n",
    "def prompt_llm_for_json(action_context: ActionContext, schema: dict, prompt: str):\n",
    "    \"\"\"\n",
    "    Have the LLM generate JSON in response to a prompt. Always use this tool when you need structured data out of the LLM.\n",
    "    This function takes a JSON schema that specifies the structure of the expected JSON response.\n",
    "    \n",
    "    Args:\n",
    "        schema: JSON schema defining the expected structure\n",
    "        prompt: The prompt to send to the LLM\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary matching the provided schema with extracted information\n",
    "    \"\"\"\n",
    "    generate_response = action_context.get(\"llm\")\n",
    "    \n",
    "    # Try up to 3 times to get valid JSON\n",
    "    for i in range(3):\n",
    "        try:\n",
    "            # Send prompt with schema instruction and get response\n",
    "            response = generate_response(Prompt(messages=[\n",
    "                {\"role\": \"system\", \n",
    "                 \"content\": f\"You MUST produce output that adheres to the following JSON schema:\\n\\n{json.dumps(schema, indent=4)}. Output your JSON in a ```json markdown block.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]))\n",
    "\n",
    "            # Check if the response has json inside of a markdown code block\n",
    "            if \"```json\" in response:\n",
    "                # Search from the front and then the back\n",
    "                start = response.find(\"```json\")\n",
    "                end = response.rfind(\"```\")\n",
    "                response = response[start+7:end].strip()\n",
    "\n",
    "            # Parse and validate the JSON response\n",
    "            return json.loads(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            if i == 2:  # On last try, raise the error\n",
    "                raise e\n",
    "            print(f\"Error generating response: {e}\")\n",
    "            print(\"Retrying...\")\n",
    "````\n",
    "\n",
    "You may have noticed a new `action_context` parameter above. Don’t worry about that for now, we will talk about this architectural choice in a later section. For now, just know that it is a context object that contains the LLM and other useful information.\n",
    "\n",
    "With this tool in place, we can extract structured data from any text input. For example, an agent processing business documents could extract information in standardized formats:\n",
    "\n",
    "From an invoice:\n",
    "\n",
    "```python\n",
    "invoice_schema = {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"invoice_number\": {\"type\": \"string\"},\n",
    "        \"date\": {\"type\": \"string\"},\n",
    "        \"amount\": {\"type\": \"number\"},\n",
    "        \"line_items\": {\n",
    "            \"type\": \"array\",\n",
    "            \"items\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"description\": {\"type\": \"string\"},\n",
    "                    \"quantity\": {\"type\": \"number\"},\n",
    "                    \"unit_price\": {\"type\": \"number\"}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "extracted_data = prompt_llm_for_json(\n",
    "    action_context=context,\n",
    "    schema=invoice_schema,\n",
    "    prompt=\"Extract invoice details from this text: 'INVOICE #1234...'\"\n",
    ")\n",
    "```\n",
    "\n",
    "The tool works by combining several key elements:\n",
    "\n",
    "* A system message that firmly instructs the LLM to adhere to the provided JSON schema\n",
    "* Retry logic to handle potential parsing failures\n",
    "* Support for both direct JSON output and markdown-formatted JSON\n",
    "* Error handling to ensure we either get valid JSON or fail explicitly\n",
    "\n",
    "It is also possible to implement this using function calling, where the LLM generates a function call with the extracted data. However, we are going to implement this using plain prompting to show you how it can be done with any LLM.\n",
    "\n",
    "The function is particularly powerful because it enforces structure through the schema while allowing flexibility in the prompt. This means we can use it for a wide variety of extraction tasks just by defining appropriate schemas. The agent can use this tool to:\n",
    "\n",
    "* Extract meeting details from emails, converting them to calendar-ready formats\n",
    "* Transform unstructured report data into structured analytics inputs\n",
    "* Convert web page content into structured product or contact information\n",
    "* Process customer communications into actionable support tickets\n",
    "\n",
    "What makes this approach especially valuable is that it creates a reliable bridge between unstructured text and structured data processing. The agent can use this tool whenever it needs to convert natural language information into a format that other systems can process programmatically. This enables workflows where the agent can:\n",
    "\n",
    "* Receive unstructured text input from various sources\n",
    "* Use `prompt_llm_for_json` to extract relevant information in a structured format\n",
    "* Pass the structured data to other APIs or services for further processing\n",
    "* Make decisions based on the processed results\n",
    "\n",
    "The tool’s retry logic and error handling make it robust enough to handle a lot of LLM variability in output, while its flexibility through schema definition makes it adaptable to new use cases without requiring changes to the core implementation.\n",
    "\n",
    "#### Balancing Flexibility and Reliability in Data Extraction\n",
    "\n",
    "When designing our agent’s toolset, we face an important architectural decision regarding data extraction. We can either rely on the agent to use the general-purpose `prompt_llm_for_json` tool with dynamically generated schemas, or we can create specialized extraction tools with fixed schemas for specific types of documents. This choice reflects a classic tradeoff between flexibility and reliability.\n",
    "\n",
    "Consider our invoice processing example. With the general-purpose approach, we’re trusting our agent to construct appropriate schemas and prompts for each situation. This provides maximum flexibility — the agent can adapt its extraction approach based on the specific context, potentially extracting different fields for different types of invoices or even handling entirely new document types without requiring new tool implementations. However, this flexibility comes with risks. The agent might generate inconsistent schemas over time, leading to data inconsistency in our database. It might miss critical fields that should always be extracted, or it might structure the data in ways that make downstream processing difficult.\n",
    "\n",
    "Let’s look at how we could create a specialized invoice extraction tool that provides more guarantees about the extracted data:\n",
    "\n",
    "```python\n",
    "@register_tool(tags=[\"document_processing\", \"invoices\"])\n",
    "def extract_invoice_data(action_context: ActionContext, document_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract standardized invoice data from document text. This tool enforces a consistent\n",
    "    schema for invoice data extraction across all documents.\n",
    "    \n",
    "    Args:\n",
    "        document_text: The text content of the invoice to process\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing extracted invoice data in a standardized format\n",
    "    \"\"\"\n",
    "    # Define a fixed schema for invoice data\n",
    "    invoice_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\"invoice_number\", \"date\", \"amount\"],  # These fields must be present\n",
    "        \"properties\": {\n",
    "            \"invoice_number\": {\"type\": \"string\"},\n",
    "            \"date\": {\"type\": \"string\", \"format\": \"date\"},\n",
    "            \"amount\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"value\": {\"type\": \"number\"},\n",
    "                    \"currency\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"value\", \"currency\"]\n",
    "            },\n",
    "            \"vendor\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"tax_id\": {\"type\": \"string\"},\n",
    "                    \"address\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            },\n",
    "            \"line_items\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"description\": {\"type\": \"string\"},\n",
    "                        \"quantity\": {\"type\": \"number\"},\n",
    "                        \"unit_price\": {\"type\": \"number\"},\n",
    "                        \"total\": {\"type\": \"number\"}\n",
    "                    },\n",
    "                    \"required\": [\"description\", \"total\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create a focused prompt that guides the LLM in invoice extraction\n",
    "    extraction_prompt = f\"\"\"\n",
    "    Extract invoice information from the following document text. \n",
    "    Focus on identifying:\n",
    "    - Invoice number (usually labeled as 'Invoice #', 'Reference', etc.)\n",
    "    - Date (any dates labeled as 'Invoice Date', 'Issue Date', etc.)\n",
    "    - Amount (total amount due, including currency)\n",
    "    - Vendor information (company name, tax ID if present, address)\n",
    "    - Line items (individual charges and their details)\n",
    "\n",
    "    Document text:\n",
    "    {document_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use our general extraction tool with the specialized schema and prompt\n",
    "    return prompt_llm_for_json(\n",
    "        action_context=action_context,\n",
    "        schema=invoice_schema,\n",
    "        prompt=extraction_prompt\n",
    "    )\n",
    "```\n",
    "\n",
    "This specialized approach offers several advantages:\n",
    "\n",
    "* **Data Consistency:** The fixed schema ensures that invoice data is always structured the same way, making it easier to work with downstream systems like databases or accounting software.\n",
    "* **Required Fields:** We can specify which fields are required, ensuring critical information is always extracted or an error is raised if it can’t be found.\n",
    "* **Field Validation:** The schema can include format specifications (like ensuring dates are properly formatted) and field-specific constraints.\n",
    "* **Focused Prompting:** We can provide detailed guidance to the LLM about where to look for specific information, improving extraction accuracy.\n",
    "\n",
    "However, this specialization also means we need to create and maintain separate extraction tools for each type of document we want to process. If we later need to handle purchase orders, receipts, or contracts, we’ll need to implement new tools for each.\n",
    "\n",
    "The choice between these approaches often depends on your specific needs:\n",
    "\n",
    "Use specialized tools when:\n",
    "\n",
    "* Data consistency is critical\n",
    "* You have a well-defined set of document types\n",
    "* You need to enforce specific validation rules\n",
    "* The extracted data feeds into other systems with strict requirements\n",
    "\n",
    "Use the general-purpose approach when:\n",
    "\n",
    "* You need to handle a wide variety of document types\n",
    "* Document formats and requirements change frequently\n",
    "* You’re prototyping or exploring new use cases\n",
    "* The downstream systems are flexible about data format\n",
    "\n",
    "In practice, many systems use a combination of both approaches: specialized tools for common, critical document types where consistency is important, and the general-purpose tool as a fallback for handling edge cases or new document types. This hybrid approach gives you the best of both worlds — reliability where you need it most, and flexibility where it matters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbcd789",
   "metadata": {},
   "source": [
    "#### A Complete Example of Prompting for Structured Data\n",
    "\n",
    "Let’s create an invoice processing system that combines specialized extraction with a simple storage mechanism. The system will use the LLM’s capabilities to understand invoice content while maintaining strict data consistency through a fixed schema.\n",
    "\n",
    "First, let’s create our specialized invoice extraction tool:\n",
    "\n",
    "```python\n",
    "@register_tool(tags=[\"document_processing\", \"invoices\"])\n",
    "def extract_invoice_data(action_context: ActionContext, document_text: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract standardized invoice data from document text.\n",
    "\n",
    "    This tool ensures consistent extraction of invoice information by using a fixed schema\n",
    "    and specialized prompting for invoice understanding. It will identify key fields like\n",
    "    invoice numbers, dates, amounts, and line items from any invoice format.\n",
    "\n",
    "    Args:\n",
    "        document_text: The text content of the invoice to process\n",
    "\n",
    "    Returns:\n",
    "        A dictionary containing the extracted invoice data in a standardized format\n",
    "    \"\"\"\n",
    "    invoice_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\"invoice_number\", \"date\", \"total_amount\"],\n",
    "        \"properties\": {\n",
    "            \"invoice_number\": {\"type\": \"string\"},\n",
    "            \"date\": {\"type\": \"string\"},\n",
    "            \"total_amount\": {\"type\": \"number\"},\n",
    "            \"vendor\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": {\"type\": \"string\"},\n",
    "                    \"address\": {\"type\": \"string\"}\n",
    "                }\n",
    "            },\n",
    "            \"line_items\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"description\": {\"type\": \"string\"},\n",
    "                        \"quantity\": {\"type\": \"number\"},\n",
    "                        \"unit_price\": {\"type\": \"number\"},\n",
    "                        \"total\": {\"type\": \"number\"}\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Create a focused prompt for invoice extraction\n",
    "    extraction_prompt = f\"\"\"\n",
    "            You are an expert invoice analyzer. Extract invoice information accurately and \n",
    "            thoroughly. Pay special attention to:\n",
    "            - Invoice numbers (look for 'Invoice #', 'No.', 'Reference', etc.)\n",
    "            - Dates (focus on invoice date or issue date)\n",
    "            - Amounts (ensure you capture the total amount correctly)\n",
    "            - Line items (capture all individual charges)\n",
    "            \n",
    "            Stop and think step by step. Then, extract the invoice data from:\n",
    "            \n",
    "            <invoice>\n",
    "            {document_text}\n",
    "            </invoice>\n",
    "    \"\"\"\n",
    "\n",
    "    # Use prompt_llm_for_json with our specialized prompt\n",
    "    return prompt_llm_for_json(\n",
    "        action_context=action_context,\n",
    "        schema=invoice_schema,\n",
    "        prompt=extraction_prompt\n",
    "    )\n",
    "```\n",
    "\n",
    "```python\n",
    "@register_tool(tags=[\"storage\", \"invoices\"])\n",
    "def store_invoice(action_context: ActionContext, invoice_data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Store an invoice in our invoice database. If an invoice with the same number\n",
    "    already exists, it will be updated.\n",
    "    \n",
    "    Args:\n",
    "        invoice_data: The processed invoice data to store\n",
    "        \n",
    "    Returns:\n",
    "        A dictionary containing the storage result and invoice number\n",
    "    \"\"\"\n",
    "    # Get our invoice storage from context\n",
    "    storage = action_context.get(\"invoice_storage\", {})\n",
    "    \n",
    "    # Extract invoice number for reference\n",
    "    invoice_number = invoice_data.get(\"invoice_number\")\n",
    "    if not invoice_number:\n",
    "        raise ValueError(\"Invoice data must contain an invoice number\")\n",
    "    \n",
    "    # Store the invoice\n",
    "    storage[invoice_number] = invoice_data\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"message\": f\"Stored invoice {invoice_number}\",\n",
    "        \"invoice_number\": invoice_number\n",
    "    }\n",
    "```\n",
    "\n",
    "Our agent includes two specialized tools that integrate to manage the invoice processing workflow:\n",
    "\n",
    "* **extract_invoice_data** acts as our intelligent document analyzer.\n",
    "  This function uses self-prompting to take raw document text and transform it into structured data following a consistent schema.\n",
    "  It uses a prompt that guides the LLM to identify crucial invoice elements like invoice numbers, dates, and line items.\n",
    "  By enforcing a fixed JSON schema with required fields, the tool ensures data consistency regardless of the original invoice format.\n",
    "  (In production, further safeguards against hallucination may be required, but this demonstrates the core functionality.)\n",
    "\n",
    "* **store_invoice** provides a simple persistence mechanism in a dictionary.\n",
    "  Once an invoice has been properly extracted and structured, this function saves it to our invoice database, using the invoice number as a unique identifier.\n",
    "  The invoices are stored separate from the memory so that they can be persisted across runs of the agent.\n",
    "\n",
    "To use this system, we would set up our agent with these tools and configure it to handle invoice processing tasks:\n",
    "\n",
    "```python\n",
    "def create_invoice_agent():\n",
    "    # Create action registry with our invoice tools\n",
    "    action_registry = PythonActionRegistry()\n",
    "    \n",
    "    # Create our base environment\n",
    "    environment = PythonEnvironment()\n",
    "    \n",
    "    # Define our invoice processing goals\n",
    "    goals = [\n",
    "        Goal(\n",
    "            name=\"Persona\",\n",
    "            description=\"You are an Invoice Processing Agent, specialized in handling and storing invoice data.\"\n",
    "        ),\n",
    "        Goal(\n",
    "            name=\"Process Invoices\",\n",
    "            description=\"\"\"\n",
    "            Your goal is to process invoices by extracting their data and storing it properly.\n",
    "            For each invoice:\n",
    "            1. Extract all important information including numbers, dates, amounts, and line items\n",
    "            2. Store the extracted data indexed by invoice number\n",
    "            3. Provide confirmation of successful processing\n",
    "            4. Handle any errors appropriately\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Create the agent\n",
    "    return Agent(\n",
    "        goals=goals,\n",
    "        agent_language=AgentFunctionCallingActionLanguage(),\n",
    "        action_registry=action_registry,\n",
    "        generate_response=generate_response,\n",
    "        environment=environment\n",
    "    )\n",
    "```\n",
    "\n",
    "This implementation provides several key benefits:\n",
    "\n",
    "* **Consistent Data Structure:**\n",
    "  The fixed schema in `extract_invoice_data` ensures all invoices are processed into a consistent format.\n",
    "  The prompting and logic for how to extract invoice data is separate from the agent’s core reasoning, making it easier to modify and maintain.\n",
    "\n",
    "* **Modular Design:**\n",
    "  Each tool has a single, clear responsibility, making the system easy to maintain and extend.\n",
    "  Details for how the tools are implemented are hidden from the overall goals of the agent.\n",
    "\n",
    "* **Error Handling:**\n",
    "  Built-in validation ensures required fields are present and data is properly formatted.\n",
    "\n",
    "* **Persistent Storage:**\n",
    "  The simple dictionary-based storage can be easily replaced with a database or other persistence mechanism by modifying the storage tools.\n",
    "  The work that the agent does can now be persisted across runs.\n",
    "\n",
    "The specialized schema and focused prompting help ensure accurate extraction, while the storage tools maintain data organization. You can extend this system by adding more specialized tools for different types of invoices or additional processing capabilities.\n",
    "\n",
    "#### Horizontal Scaling of Agents Through Tools\n",
    "\n",
    "One of the most powerful aspects of this tool-based approach is how it enables horizontal scaling of agent capabilities. Rather than constantly expanding the core goals or system prompt of an agent — which can lead to prompt bloat and conflicting instructions — we can encapsulate specific functionality in well-defined tools that the agent can access as needed.\n",
    "\n",
    "#### Encapsulating Complexity in Tools\n",
    "\n",
    "Tools serve as specialized modules that hide implementation complexity from the agent’s core reasoning. Consider our invoice processing example:\n",
    "\n",
    "* **Abstraction of Domain Knowledge:**\n",
    "  The `extract_invoice_data` tool encapsulates specialized knowledge about invoice formats, field identification, and data extraction.\n",
    "  The agent doesn’t need to understand these details — it just needs to know when to use the tool.\n",
    "\n",
    "* **Separation of Concerns:**\n",
    "  Each tool handles a specific function (extraction, storage), allowing the agent to focus on high-level coordination rather than implementation specifics.\n",
    "  This separation makes the entire system more maintainable and easier to reason about.\n",
    "\n",
    "* **Focused Prompting:**\n",
    "  By moving specialized prompting inside tools, we keep the agent’s core goals simple and focused.\n",
    "  The extraction tool handles its own specialized prompt engineering, freeing the agent from needing to generate perfect prompts for every task.\n",
    "\n",
    "#### Maintainability and Adaptability\n",
    "\n",
    "Tools create a modular architecture that offers significant maintenance advantages:\n",
    "\n",
    "* **Independent Development:**\n",
    "  Tools can be developed, tested, and improved independently of the agent’s core logic.\n",
    "  Specialized teams can work on different tools without needing to understand or modify the entire agent system.\n",
    "\n",
    "* **Versioning and Updates:**\n",
    "  Individual tools can be updated without changing the agent’s core goals.\n",
    "  For example, we could improve the invoice extraction algorithm without touching any other part of the system.\n",
    "\n",
    "* **Plug-and-Play Functionality:**\n",
    "  New capabilities can be added by simply registering new tools with the action registry.\n",
    "  The agent automatically gains access to these capabilities through its function-calling abilities.\n",
    "\n",
    "#### Adapting Agents Through Tool Management\n",
    "\n",
    "This architecture makes it remarkably easy to adapt agents for different use cases:\n",
    "\n",
    "* **Tool Composition:**\n",
    "  Create specialized agents by selecting which tools they have access to.\n",
    "  An invoice processing agent might have document tools, while a customer service agent might have access to CRM tools.\n",
    "\n",
    "* **Capability Evolution:**\n",
    "  Start with simple implementations and gradually enhance capabilities by upgrading tools.\n",
    "  For example, our simple dictionary-based invoice storage could be replaced with a database connector without changing the agent’s core logic.\n",
    "\n",
    "* **Context Management:**\n",
    "  Tools can manage their own state and context, reducing the cognitive load on the agent.\n",
    "  In our example, the storage tool manages its own data structure, allowing the agent to focus on process flow rather than data management.\n",
    "\n",
    "#### Practical Implementation Considerations\n",
    "\n",
    "When implementing a tool-based architecture for horizontal scaling:\n",
    "\n",
    "* **Tool Discoverability:**\n",
    "  Ensure tools have clear descriptions and tags so the agent can understand when to use them.\n",
    "  Well-documented tool interfaces help both human developers and AI agents.\n",
    "\n",
    "* **Error Handling:**\n",
    "  Build robust error handling into tools to prevent failures from cascading through the system.\n",
    "  Tools should provide clear error messages that guide the agent toward resolution.\n",
    "\n",
    "* **Instrumentation:**\n",
    "  Add logging and monitoring to tools to track their usage and performance.\n",
    "  This provides valuable insights for improving both the tools and the agent’s decision-making about when to use them.\n",
    "\n",
    "* **Contextual Awareness:**\n",
    "  Design tools to preserve and utilize context when appropriate.\n",
    "  For example, our invoice storage tool could be enhanced to track modification history or flag unusual changes.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Horizontal scaling through tools represents a paradigm shift in how we build and evolve agent systems. Rather than creating monolithic agents with ever-expanding capabilities encoded in their core prompts, we can build modular, adaptable systems that grow through the addition of specialized tools.\n",
    "\n",
    "This approach mirrors successful software engineering practices — encapsulation, modularity, and separation of concerns — applied to the unique challenges of LLM-based agents. By focusing complexity in tools rather than core agent reasoning, we create systems that are more maintainable, more adaptable, and ultimately more capable of solving complex, real-world problems.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
