{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2a602b",
   "metadata": {},
   "source": [
    "# Improve agentic reasoning\n",
    "\n",
    "* in-context learning\n",
    "    * one-shot, few-shots learning (examples of using tools and/or reasoning)\n",
    "    * LLM as pattern completion/following machines\n",
    "\n",
    "* reasoning, up-front planning, and chain of thought\n",
    "    * build a plan before doing anything, step-by-step\n",
    "        * go and run the plan\n",
    "            * turn into code, workflow language\n",
    "            * repeatability (save and re-run the code)\n",
    "        * put the plan into memory\n",
    "            * execute actions one at the time\n",
    "            * flexible reaction on errors\n",
    "        * planning as a tool\n",
    "            * generate the plan using expensive hi-quality model\n",
    "            * saves on execution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e192921",
   "metadata": {},
   "source": [
    "### Extending the Agent Loop with Capabilities\n",
    "\n",
    "The **Capability** pattern lets you extend core agent behavior without modifying the agent loop. Each capability encapsulates a focused adaptation (e.g., logging, time-awareness, metrics), plugs into lifecycle hooks, and cleanly composes with others. This keeps the loop minimal while enabling rich behaviors like opening DB connections, logging LLM prompts, or injecting metadata.\n",
    "\n",
    "#### Interaction Points in the Agent Loop\n",
    "\n",
    "```python\n",
    "def run(self, user_input: str, memory=None, action_context_props=None):\n",
    "    # ... existing code ...\n",
    "\n",
    "    # Initialize capabilities\n",
    "    for capability in self.capabilities:\n",
    "        capability.init(self, action_context)\n",
    "        \n",
    "    while True:\n",
    "        # Start-of-loop\n",
    "        can_start_loop = reduce(lambda a, c: c.start_agent_loop(self, action_context),\n",
    "                               self.capabilities, False)\n",
    "\n",
    "        # Build prompt\n",
    "        prompt = reduce(lambda p, c: c.process_prompt(self, action_context, p),\n",
    "                        self.capabilities, base_prompt)\n",
    "\n",
    "        # Process LLM response\n",
    "        response = reduce(lambda r, c: c.process_response(self, action_context, r),\n",
    "                          self.capabilities, response)\n",
    "\n",
    "        # Process parsed action\n",
    "        action = reduce(lambda a, c: c.process_action(self, action_context, a),\n",
    "                        self.capabilities, action)\n",
    "\n",
    "        # Execute & post-process result\n",
    "        result = reduce(lambda r, c: c.process_result(self, action_context, response,\n",
    "                                                      action_def, action, r),\n",
    "                        self.capabilities, result)\n",
    "\n",
    "        # End-of-loop\n",
    "        for capability in self.capabilities:\n",
    "            capability.end_agent_loop(self, action_context)\n",
    "```\n",
    "\n",
    "#### Capability Interface\n",
    "\n",
    "```python\n",
    "class Capability:\n",
    "    def __init__(self, name: str, description: str):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "\n",
    "    def init(self, agent, action_context: ActionContext) -> dict: ...\n",
    "    def start_agent_loop(self, agent, action_context: ActionContext) -> bool: return True\n",
    "    def process_prompt(self, agent, action_context: ActionContext, prompt: Prompt) -> Prompt: return prompt\n",
    "    def process_response(self, agent, action_context: ActionContext, response: str) -> str: return response\n",
    "    def process_action(self, agent, action_context: ActionContext, action: dict) -> dict: return action\n",
    "    def process_result(self, agent, action_context: ActionContext, response: str, action_def: Action,\n",
    "                       action: dict, result: any) -> any: return result\n",
    "    def process_new_memories(self, agent, action_context: ActionContext, memory: Memory,\n",
    "                             response, result, memories: List[dict]) -> List[dict]: return memories\n",
    "    def end_agent_loop(self, agent, action_context: ActionContext): ...\n",
    "    def should_terminate(self, agent, action_context: ActionContext, response: str) -> bool: return False\n",
    "    def terminate(self, agent, action_context: ActionContext) -> dict: ...\n",
    "```\n",
    "\n",
    "**Lifecycle cheat sheet**\n",
    "\n",
    "* **init**: one-time setup (e.g., seed memory, open connections).\n",
    "* **start_agent_loop**: pre-iteration checks (e.g., rate limits).\n",
    "* **process_prompt**: mutate/augment prompts pre-LLM (e.g., add time).\n",
    "* **process_response**: validate/sanitize raw LLM text.\n",
    "* **process_action**: enrich/validate planned actions.\n",
    "* **process_result**: annotate/transform tool results.\n",
    "* **process_new_memories**: redact/augment memories before storing.\n",
    "* **end_agent_loop**: cleanup/logging per iteration.\n",
    "* **should_terminate / terminate**: graceful shutdown & finalization.\n",
    "\n",
    "#### Composing Capabilities into an Agent\n",
    "\n",
    "```python\n",
    "class Agent:\n",
    "    def __init__(self,\n",
    "                 goals: List[Goal],\n",
    "                 agent_language: AgentLanguage,\n",
    "                 action_registry: ActionRegistry,\n",
    "                 generate_response: Callable[[Prompt], str],\n",
    "                 environment: Environment,\n",
    "                 capabilities: List[Capability] = [],\n",
    "                 max_iterations: int = 10,\n",
    "                 max_duration_seconds: int = 180):\n",
    "        self.goals = goals\n",
    "        self.generate_response = generate_response\n",
    "        self.agent_language = agent_language\n",
    "        self.actions = action_registry\n",
    "        self.environment = environment\n",
    "        self.capabilities = capabilities or []\n",
    "        self.max_iterations = max_iterations\n",
    "        self.max_duration_seconds = max_duration_seconds\n",
    "```\n",
    "\n",
    "```python\n",
    "agent = Agent(\n",
    "    goals=[Goal(name=\"scheduling\", description=\"Schedule meetings considering current time and availability\")],\n",
    "    agent_language=JSONAgentLanguage(),\n",
    "    action_registry=registry,\n",
    "    generate_response=llm.generate,\n",
    "    environment=PythonEnvironment(),\n",
    "    capabilities=[\n",
    "        TimeAwareCapability(),\n",
    "        LoggingCapability(log_level=\"INFO\"),\n",
    "        MetricsCapability(metrics_server=\"prometheus:9090\"),\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "*Order matters*: each capability sees and may modify the artifact before it reaches the next capability (middleware-style).\n",
    "\n",
    "---\n",
    "\n",
    "### Implementing Time Awareness\n",
    "\n",
    "Make the agent consistently aware of current time for better scheduling, deadline handling, and time-sensitive decisions.\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "class TimeAwareCapability(Capability):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Time Awareness\", description=\"Allows the agent to be aware of time\")\n",
    "\n",
    "    def init(self, agent, action_context: ActionContext) -> dict:\n",
    "        tz_name = action_context.get(\"time_zone\", \"America/Chicago\")\n",
    "        now = datetime.now(ZoneInfo(tz_name))\n",
    "        iso_time = now.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        human_time = now.strftime(\"%H:%M %A, %B %d, %Y\")\n",
    "\n",
    "        memory = action_context.get_memory()\n",
    "        memory.add_memory({\n",
    "            \"type\": \"system\",\n",
    "            \"content\": (\n",
    "                f\"Right now, it is {human_time} (ISO: {iso_time}). \"\n",
    "                f\"You are in the {tz_name} timezone. \"\n",
    "                \"Please consider the day/time, if relevant, when responding.\"\n",
    "            )\n",
    "        })\n",
    "\n",
    "    def process_prompt(self, agent, action_context: ActionContext, prompt: Prompt) -> Prompt:\n",
    "        tz_name = action_context.get(\"time_zone\", \"America/Chicago\")\n",
    "        now = datetime.now(ZoneInfo(tz_name))\n",
    "        system_msg = f\"Current time: {now.strftime('%H:%M %A, %B %d, %Y')} ({tz_name})\\n\\n\"\n",
    "\n",
    "        messages = prompt.messages\n",
    "        if messages and messages[0][\"role\"] == \"system\":\n",
    "            messages[0][\"content\"] = system_msg + messages[0][\"content\"]\n",
    "        else:\n",
    "            messages.insert(0, {\"role\": \"system\", \"content\": system_msg})\n",
    "        return Prompt(messages=messages)\n",
    "```\n",
    "\n",
    "**Example behavior**\n",
    "\n",
    "```\n",
    "agent.run(\"Schedule a team meeting for today\")\n",
    "# → \"Since it's already 5:30 PM on Friday, I recommend Monday morning. Should I check availability for Monday?\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Extending Time Awareness\n",
    "\n",
    "Track execution timestamps and durations for actions and results.\n",
    "\n",
    "```python\n",
    "class EnhancedTimeAwareCapability(TimeAwareCapability):\n",
    "    def process_action(self, agent, action_context: ActionContext, action: dict) -> dict:\n",
    "        action[\"execution_time\"] = datetime.now(\n",
    "            ZoneInfo(action_context.get(\"time_zone\", \"America/Chicago\"))\n",
    "        ).isoformat()\n",
    "        return action\n",
    "\n",
    "    def process_result(self, agent, action_context: ActionContext, response: str,\n",
    "                       action_def: Action, action: dict, result: any) -> any:\n",
    "        if isinstance(result, dict) and \"execution_time\" in action:\n",
    "            start = datetime.fromisoformat(action[\"execution_time\"])\n",
    "            end = datetime.now(ZoneInfo(action_context.get(\"time_zone\", \"America/Chicago\")))\n",
    "            result[\"action_duration\"] = (end - start).total_seconds()\n",
    "        return result\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Why the Capability Pattern Works\n",
    "\n",
    "* **Separation of concerns**: core loop stays small; features live in focused classes.\n",
    "* **Composability**: mix-and-match behaviors (time, logging, metrics, safety).\n",
    "* **Testability**: unit-test capabilities in isolation; mock `ActionContext`.\n",
    "* **Observability & governance**: capabilities can add audit logs, PII redaction, or policy checks without touching loop logic.\n",
    "\n",
    "Use capabilities whenever a concern cuts across multiple phases of the loop (prompting, actions, results, memory). Keep each capability single-purpose, and order them intentionally to get predictable, maintainable behavior.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4725eddd",
   "metadata": {},
   "source": [
    "### Plan First: a Capability that makes the agent think before acting\n",
    "\n",
    "Below is a clean, drop-in implementation of a **PlanFirstCapability** plus a robust `create_plan` tool. It fixes small issues (e.g., `_memory` → `memory`), keeps your agent loop untouched, and stores the generated plan in memory so later turns can reference it. Optional progress tracking is included.\n",
    "\n",
    "#### Capability\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "from typing import Optional, List\n",
    "\n",
    "class PlanFirstCapability(Capability):\n",
    "    def __init__(self, plan_memory_type: str = \"system\", track_progress: bool = False):\n",
    "        super().__init__(\n",
    "            name=\"Plan First Capability\",\n",
    "            description=\"The Agent will always create a plan and add it to memory\"\n",
    "        )\n",
    "        self.plan_memory_type = plan_memory_type\n",
    "        self.track_progress = track_progress\n",
    "        self._initialized = False\n",
    "\n",
    "    def _get_mem_items(self, memory: \"Memory\") -> List[dict]:\n",
    "        # compatible with either .items or .get_memories()\n",
    "        return getattr(memory, \"items\", None) or memory.get_memories()\n",
    "\n",
    "    def init(self, agent, action_context: ActionContext):\n",
    "        if self._initialized:\n",
    "            return\n",
    "        self._initialized = True\n",
    "\n",
    "        mem = action_context.get_memory()\n",
    "        action_registry = action_context.get(\"action_registry\") or action_context.get_action_registry()\n",
    "\n",
    "        plan_text = create_plan(\n",
    "            action_context=action_context,\n",
    "            memory=mem,\n",
    "            action_registry=action_registry\n",
    "        )\n",
    "\n",
    "        mem.add_memory({\n",
    "            \"type\": self.plan_memory_type,\n",
    "            \"content\": \"You must follow these instructions carefully to complete the task:\\n\" + plan_text,\n",
    "        })\n",
    "\n",
    "        if self.track_progress:\n",
    "            mem.add_memory({\n",
    "                \"type\": \"system\",\n",
    "                \"content\": \"Planning initialized. Track progress by appending step completions to memory under type=progress.\"\n",
    "            })\n",
    "\n",
    "    def process_prompt(self, agent, action_context: ActionContext, prompt: \"Prompt\") -> \"Prompt\":\n",
    "        \"\"\"Light reminder to follow the plan at each turn.\"\"\"\n",
    "        mem = action_context.get_memory()\n",
    "        # grab the latest stored plan (if multiple, keep the last)\n",
    "        plan_msgs = [m for m in self._get_mem_items(mem) if \"instructions carefully\" in m.get(\"content\", \"\")]\n",
    "        if plan_msgs:\n",
    "            plan_head = \"Follow the stored plan. If a step is complete, move to the next; otherwise add needed info.\\n\\n\"\n",
    "            if prompt.messages and prompt.messages[0].get(\"role\") == \"system\":\n",
    "                prompt.messages[0][\"content\"] = plan_head + prompt.messages[0][\"content\"]\n",
    "            else:\n",
    "                prompt.messages.insert(0, {\"role\": \"system\", \"content\": plan_head})\n",
    "        return prompt\n",
    "\n",
    "    def process_result(self, agent, action_context: ActionContext, response: str, action_def: \"Action\",\n",
    "                       action: dict, result: any) -> any:\n",
    "        \"\"\"Optionally track progress after tool execution.\"\"\"\n",
    "        if not self.track_progress:\n",
    "            return result\n",
    "        mem = action_context.get_memory()\n",
    "        step_name = (action or {}).get(\"tool\") or (action_def.name if hasattr(action_def, \"name\") else \"unknown_action\")\n",
    "        mem.add_memory({\n",
    "            \"type\": \"progress\",\n",
    "            \"content\": f\"Completed step via `{step_name}` at {datetime.utcnow().isoformat()}Z\"\n",
    "        })\n",
    "        return result\n",
    "```\n",
    "\n",
    "#### Planning tool\n",
    "\n",
    "```python\n",
    "@register_tool(tags=[\"planning\"], description=\"Create a detailed execution plan based on the task and available tools\")\n",
    "def create_plan(action_context: ActionContext,\n",
    "                memory: \"Memory\",\n",
    "                action_registry: \"ActionRegistry\") -> str:\n",
    "    \"\"\"Create a detailed execution plan based on the task and available tools.\"\"\"\n",
    "\n",
    "    # Gather tool descriptions for the LLM\n",
    "    try:\n",
    "        actions = action_registry.get_actions()\n",
    "    except AttributeError:\n",
    "        actions = getattr(action_registry, \"actions\", [])  # fallback\n",
    "    tool_descriptions = \"\\n\".join(\n",
    "        f\"- {getattr(a, 'name', getattr(a, 'tool', 'tool'))}: {getattr(a, 'description', '')}\"\n",
    "        for a in actions\n",
    "    ) or \"- (no tools registered)\"\n",
    "\n",
    "    # Pull relevant memory (user/system) to ground the plan\n",
    "    mem_items = getattr(memory, \"items\", None) or memory.get_memories()\n",
    "    memory_content = \"\\n\".join(\n",
    "        f\"{m.get('type', 'unknown')}: {m.get('content', '')}\"\n",
    "        for m in mem_items\n",
    "        if m.get(\"type\") in (\"user\", \"system\")\n",
    "    ) or \"(no prior task context)\"\n",
    "\n",
    "    prompt = f\"\"\"Given the task in memory and the available tools, create a detailed plan.\n",
    "Think through this step by step:\n",
    "\n",
    "1. Identify the key components of the task\n",
    "2. Consider what tools you have available\n",
    "3. Break down the task into logical steps\n",
    "4. For each step, specify:\n",
    "   - What needs to be done\n",
    "   - What tool(s) will be used\n",
    "   - What information is needed\n",
    "   - What the expected outcome is\n",
    "\n",
    "Write your plan in clear, numbered steps. Each step should be specific and actionable.\n",
    "\n",
    "Available tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "Task context from memory:\n",
    "{memory_content}\n",
    "\n",
    "Create a plan that accomplishes this task effectively.\"\"\"\n",
    "    # Call the LLM via context\n",
    "    llm = action_context.get(\"llm\")\n",
    "    if not llm:\n",
    "        raise ValueError(\"No LLM found in ActionContext under key 'llm'\")\n",
    "    return llm(prompt)\n",
    "```\n",
    "\n",
    "#### Wiring (what the agent needs)\n",
    "\n",
    "Make sure your `ActionContext` provides the LLM, memory, and the action registry so the capability can generate its plan:\n",
    "\n",
    "```python\n",
    "agent = Agent(\n",
    "    goals=[Goal(name=\"analysis\", description=\"Analyze sales data and create a report\")],\n",
    "    agent_language=JSONAgentLanguage(),\n",
    "    action_registry=registry,\n",
    "    generate_response=llm.generate,\n",
    "    environment=PythonEnvironment(),\n",
    "    capabilities=[PlanFirstCapability(track_progress=True)]\n",
    ")\n",
    "\n",
    "# When you run:\n",
    "# - Your agent loop should build an ActionContext that includes:\n",
    "#   {\"memory\": memory, \"llm\": llm.generate, \"action_registry\": registry, ...}\n",
    "result = agent.run(\"Analyze our Q4 sales data and create a report\")\n",
    "```\n",
    "\n",
    "#### Notes & best practices\n",
    "\n",
    "* **Separation of concerns**: the capability composes planning into the loop; the loop stays unchanged.\n",
    "* **Idempotence**: `init` runs once per agent run to avoid duplicate plans.\n",
    "* **Robustness**: the tool works with either `memory.items` or `memory.get_memories()`.\n",
    "* **Progress tracking** (optional): writes `type=\"progress\"` memories after each action, useful for audits and UI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaa5e7d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## In-loop planning\n",
    "\n",
    "* in planning ahead, the planning is not necessary the focus at the end of the execution\n",
    "* another approach\n",
    "    * create a plan\n",
    "        * at the end of iteration, create progress report\n",
    "            * where are we on the plan,\n",
    "            * what was done,\n",
    "            * what is next\n",
    "            * can be done every iteration, of at every 5th..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8214ed24",
   "metadata": {},
   "source": [
    "### Tracking Progress: Capability + Tool\n",
    "\n",
    "Below is a polished, drop-in implementation of a **`track_progress`** tool and a **`ProgressTrackingCapability`** that appends a concise reflection at the **end of each loop iteration**. It fixes minor issues (`_memory` → `memory`), supports dependency injection via `ActionContext`, and lets you control frequency and memory type.\n",
    "\n",
    "#### Progress tool\n",
    "\n",
    "```python\n",
    "@register_tool(tags=[\"prompts\"], description=\"Summarize progress and recommend next steps\")\n",
    "def track_progress(action_context: ActionContext,\n",
    "                   memory: \"Memory\",\n",
    "                   action_registry: \"ActionRegistry\") -> str:\n",
    "    \"\"\"Generate a progress report based on the current task, available tools, and memory context.\"\"\"\n",
    "\n",
    "    # 1) Tool catalog\n",
    "    try:\n",
    "        actions = action_registry.get_actions()\n",
    "    except AttributeError:\n",
    "        actions = getattr(action_registry, \"actions\", [])\n",
    "    tool_descriptions = \"\\n\".join(\n",
    "        f\"- {getattr(a, 'name', getattr(a, 'tool', 'tool'))}: {getattr(a, 'description', '')}\"\n",
    "        for a in actions\n",
    "    ) or \"- (no tools registered)\"\n",
    "\n",
    "    # 2) Relevant memory (user/system + latest progress/status/results if you keep those types)\n",
    "    mem_items = getattr(memory, \"items\", None) or memory.get_memories()\n",
    "    relevant_types = {\"user\", \"system\", \"progress\", \"status\", \"result\"}\n",
    "    memory_content = \"\\n\".join(\n",
    "        f\"{m.get('type','unknown')}: {m.get('content','')}\"\n",
    "        for m in mem_items\n",
    "        if m.get(\"type\") in relevant_types\n",
    "    ) or \"(no prior task context)\"\n",
    "\n",
    "    # 3) Prompt\n",
    "    prompt = f\"\"\"Given the current task and available tools, generate a progress report.\n",
    "Think step by step:\n",
    "\n",
    "1) Identify key components of the task and intended outcome.\n",
    "2) Assess progress so far from the provided context.\n",
    "3) Identify blockers or issues.\n",
    "4) Recommend concrete next steps.\n",
    "5) Suggest any tool usage to advance.\n",
    "\n",
    "Write using short, structured bullets: Progress • Blockers • Next Steps • Suggested Tools.\n",
    "\n",
    "Available tools:\n",
    "{tool_descriptions}\n",
    "\n",
    "Task context from memory:\n",
    "{memory_content}\n",
    "\n",
    "Return only the report text.\"\"\"\n",
    "    llm = action_context.get(\"llm\")\n",
    "    if not llm:\n",
    "        raise ValueError(\"No LLM found in ActionContext under key 'llm'\")\n",
    "    return llm(prompt)\n",
    "```\n",
    "\n",
    "#### Capability\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "\n",
    "class ProgressTrackingCapability(Capability):\n",
    "    def __init__(self,\n",
    "                 memory_type: str = \"system\",\n",
    "                 track_frequency: int = 1,\n",
    "                 max_report_chars: int = 2000,\n",
    "                 tag: str = \"Progress Report\"):\n",
    "        \"\"\"\n",
    "        memory_type: where to store reports (e.g., 'system'/'progress')\n",
    "        track_frequency: run every N iterations (1 = every loop)\n",
    "        max_report_chars: truncate very long reports to bound token cost\n",
    "        tag: label inserted into memory for easier retrieval\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name=\"Progress Tracking\",\n",
    "            description=\"Tracks progress and enables reflection after actions\"\n",
    "        )\n",
    "        self.memory_type = memory_type\n",
    "        self.track_frequency = max(1, int(track_frequency))\n",
    "        self.max_report_chars = max(200, int(max_report_chars))\n",
    "        self.tag = tag\n",
    "        self.iteration_count = 0\n",
    "\n",
    "    def end_agent_loop(self, agent, action_context: ActionContext):\n",
    "        \"\"\"Generate and store a progress report at the end of selected iterations.\"\"\"\n",
    "        self.iteration_count += 1\n",
    "        if self.iteration_count % self.track_frequency != 0:\n",
    "            return\n",
    "\n",
    "        mem = action_context.get_memory()\n",
    "        # You can inject either via context or a helper:\n",
    "        action_registry = (action_context.get(\"action_registry\")\n",
    "                           or action_context.get_action_registry())\n",
    "\n",
    "        try:\n",
    "            report = track_progress(\n",
    "                action_context=action_context,\n",
    "                memory=mem,\n",
    "                action_registry=action_registry\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Log into memory for observability without crashing the loop\n",
    "            mem.add_memory({\n",
    "                \"type\": \"system\",\n",
    "                \"content\": f\"[{self.tag}] Error generating progress report: {e}\"\n",
    "            })\n",
    "            return\n",
    "\n",
    "        if not isinstance(report, str):\n",
    "            report = str(report)\n",
    "\n",
    "        # Hard cap to keep costs predictable\n",
    "        if len(report) > self.max_report_chars:\n",
    "            report = report[: self.max_report_chars] + \" …[truncated]\"\n",
    "\n",
    "        mem.add_memory({\n",
    "            \"type\": self.memory_type,\n",
    "            \"content\": f\"{self.tag} (Iteration {self.iteration_count}, UTC {datetime.utcnow().isoformat()}Z):\\n{report}\"\n",
    "        })\n",
    "\n",
    "    # Optional: surface termination hint if repeated blockers detected\n",
    "    def should_terminate(self, agent, action_context: ActionContext, response: str) -> bool:\n",
    "        \"\"\"Example heuristic: if the last N reports mention 'blocked' repeatedly, suggest stop.\"\"\"\n",
    "        # Keep it disabled by default; implement if you maintain blocker counters in memory.\n",
    "        return False\n",
    "```\n",
    "\n",
    "#### Wiring into your agent\n",
    "\n",
    "```python\n",
    "agent = Agent(\n",
    "    goals=[Goal(name=\"data_processing\", description=\"Process and analyze customer feedback data\")],\n",
    "    agent_language=JSONAgentLanguage(),\n",
    "    action_registry=registry,\n",
    "    generate_response=llm.generate,\n",
    "    environment=PythonEnvironment(),\n",
    "    capabilities=[\n",
    "        ProgressTrackingCapability(\n",
    "            memory_type=\"progress\",     # or \"system\"\n",
    "            track_frequency=2,          # reflect every 2nd iteration\n",
    "            max_report_chars=1500,\n",
    "            tag=\"Progress Report\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Ensure your ActionContext includes:\n",
    "# {\"memory\": memory, \"llm\": llm.generate, \"action_registry\": registry, ...}\n",
    "result = agent.run(\"Analyze customer feedback from Q4 and identify top issues\")\n",
    "```\n",
    "\n",
    "#### Practical tips\n",
    "\n",
    "* **Cost control:** Use `track_frequency`, `max_report_chars`, and concise output instructions to bound tokens.\n",
    "* **Signal over noise:** Store reports under a dedicated `type` (e.g., `\"progress\"`) so downstream steps can quickly fetch recent reflections without scanning all memory.\n",
    "* **Close the loop:** When planning the next action, have your planner/selective-context step include the **latest progress report** to avoid repeating completed work and to address blockers promptly.\n",
    "* **Security:** If memory may contain sensitive data, add a redaction capability before storing reports (e.g., mask PII).\n",
    "\n",
    "This pattern adds a lightweight “**act → reflect → adjust**” rhythm to the agent, improving robustness on long, multi-tool workflows without polluting the core loop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6c7f1d",
   "metadata": {},
   "source": [
    "## Ahead of time vs dynamic\n",
    "\n",
    "* execution styles\n",
    "    * agent decides every-step what to do next\n",
    "        * adaptive\n",
    "        * flexible\n",
    "        * expensive\n",
    "        * slow\n",
    "        * unpredictable\n",
    "        * error prone\n",
    "    * up-front planning, code or workflow generated\n",
    "        * no control once the plan is generated\n",
    "        * rigid\n",
    "        * fast\n",
    "        * predictable\n",
    "        * cheap\n",
    "    * hybrid\n",
    "        * up-front planning\n",
    "        * on error/problem generate adaptive response\n",
    "    * shim\n",
    "        * agent validating inputs to the next step"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
